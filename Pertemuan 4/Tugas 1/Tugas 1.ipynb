{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soal 1\n",
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data Tugas 1.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek apakah ada baris duplikat\n",
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jika ada baris yang terduplikat, hapus baris duplikat tersebut.\n",
    "# Jangan lupa untuk me-reset nilai index\n",
    "df = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek akan jumlah keberadaan missing value pada tiap kolom\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isi missing value pada variabel bedrooms, bathrooms, floors, dan year_built dengan nilai median dari setiap variabel menggunakan looping\n",
    "\n",
    "# Buat list variable yang akan diisi\n",
    "variable = ['bedrooms', 'bathrooms', 'floors', 'year_built']\n",
    "\n",
    "for cols in variable:\n",
    "\n",
    "    # Isi variable dengan nilai median\n",
    "    median = pass\n",
    "    pass = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isi missing value pada variabel certificate, property_condition, building_orientation, dan furnishing dengan nilai modus dari setiap variabel menggunakan looping\n",
    "# Gunakan langkah yang sama seperti sebelumnya\n",
    "\n",
    "variable = ['certificate', 'property_condition', 'building_orientation', 'furnishing']\n",
    "\n",
    "for cols in variable:\n",
    "    modus = pass[0]\n",
    "    df[cols] = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isi missing value pada variabel yang tersisa dengan nilai rata-rata\n",
    "\n",
    "variable = ['land_size_m2', 'building_size_m2']\n",
    "\n",
    "for cols in variable:\n",
    "    avg = pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat variabel yang menunjukkan usia bangunan, dan hapus variabel year_built\n",
    "\n",
    "df['building_age'] = pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabel address berisikan Desa/Wilayah dan Kota dari suatu bangunan\n",
    "# Pisahkan Desa dengan Kota menjadi 2 kolom yang berbeda, kemudian hapus variabel address\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan setiap fasilitas yang ada pada facilities, dan simpan tiap baris sebagai list\n",
    "split = pass\n",
    "\n",
    "# Looping dengan range banyaknya baris pada dataframe\n",
    "for i in pass:\n",
    "\n",
    "    # Hapus spasi yang berlebih pada tiap fasilitas, dan simpan dalam split[i]\n",
    "    # Gunakan list comprehension\n",
    "    split[i] = pass\n",
    "\n",
    "    # Buat list kosong\n",
    "    new_list = pass\n",
    "\n",
    "    # Buat looping untuk menghilangkan duplikasi fasilitas pada suatu list\n",
    "    for item in split[i]:\n",
    "\n",
    "        # Gunakan kondisi ketika item tidak ada di list yang kosong dan jika item setidaknya memiliki 1 huruf\n",
    "        if (pass) and (pass):\n",
    "\n",
    "            # Tambahkan item ke dalam list kosong\n",
    "            pass\n",
    "    \n",
    "    # Perbarui split[i] dengan new_list\n",
    "    pass = pass\n",
    "\n",
    "# Perbarui facilities dengan split\n",
    "pass = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabel electricity masih memiliki satuan di dalam kolom\n",
    "# Ubahlah sedemikian rupa supaya variabel electricity hanya menyimpan angka\n",
    "# Note: Jika baris tidak memiliki angka sama sekali, anggap saja nilainya 0\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dan install library disini\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buatlah dummy untuk variabel Desa, Kota, certificate, property_condition, building orientation, dan furnishing\n",
    "\n",
    "pass\n",
    "\n",
    "# Gabungkan variabel dummy dengan data asli\n",
    "# Kemudian hapus variabel Desa, Kota, certificate, property_condition, building orientation, dan furnishing\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ubah variabel facilities menjadi binary seperti gambar di bawah ini\n",
    "Hint: Dapat menggunakan salah satu function dari sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IMAGE](https://raw.githubusercontent.com/ArviandanaR/Praktikum-Data-Mining-2024/main/Pertemuan%204/Image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan langkah seperti di atas, kemudian gabungkan dengan data asli\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soal 2\n",
    "# **Association Rules**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda diminta untuk membuat Sistem Rekomendasi Film menggunakan Association Rules untuk dataset yang diberikan. Dataset yang diberikan adalah dataset MovieLens. Dataset ini berisi informasi mengenai film-film, rating pengguna, tag, dll. Anda diminta untuk membangun sistem rekomendasi yang dapat memberikan rekomendasi untuk film-film yang mungkin ingin dilihat pelanggan berdasarkan film-film yang sudah ditonton sebelumnya.\n",
    "\n",
    "Dataset yang digunakan adalah dataset MovieLens (ml-25m) yang berisi rating bintang 5 dan aktivitas tagging teks bebas dari MovieLens, sebuah layanan rekomendasi film. Dataset ini berisi 27753444 rating dan 1.129 aplikasi tag dari sekitar 62.000 film. Data ini dibuat oleh 162.000 pengguna dan dirilis pada Desember 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Tugas Anda adalah sebagai berikut:**</span><br>\n",
    "- Lakukan preprocessing dataset untuk membuat daftar transaksional di mana setiap baris mewakili seorang pengguna dan film-film yang dipilihnya.\n",
    "- Transformasi daftar gabungan film yang telah telah dilakukan preprocessing sebelumnya menjadi binary input.\n",
    "- Frequent Itemset Mining: Gunakan algoritma FP-Growth dan Apriori untuk menemukan item-item yang sering muncul bersama dalam dataset.\n",
    "    - Kode Algoritma Apriori\n",
    "    - Berikan Penjelasan tentang hasilnya\n",
    "    - Kode Algoritma FP-Growth\n",
    "    - Berikan Penjelasan tentang hasilnya\n",
    "- Gunakan itemset frekuensi yang ditemukan untuk menemukan aturan asosiasi antara item yang muncul bersama dalam dataset.\n",
    "    - Kode Aturan Asosiasi\n",
    "    - Urutkan nilai berdasarkan nilai confidence dan lift\n",
    "    - Berikan Penjelasan tentang hasilnya\n",
    "- Jalankan Semua Kode\n",
    "\n",
    "Tulis kode Anda di dalam $pass$ dan jangan mengubah nama variabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Dataset$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengimpor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Data Using request, must be executed, and will add the dataset to your main directory.\n",
    "import requests, zipfile, io\n",
    "zipfile.ZipFile(io.BytesIO(requests.get('https://files.grouplens.org/datasets/movielens/ml-25m.zip').content)).extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -a ml-25m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies = pd.read_csv('ml-25m/movies.csv')\n",
    "data_tages = pd.read_csv('ml-25m/tags.csv')\n",
    "data_ratings = pd.read_csv('ml-25m/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Film** <br>\n",
    "Dataset ini berisi judul film dan unique value dari setiap film tanpa nilai duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies.movieId.value_counts(), print('Number of duplicated unique ids are: ',data_movies.movieId.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Tages Film** <br>\n",
    "Dataset ini berisi tag yang ditambahkan ke film ditambah dengan ID pengguna yang bernilai untuk dipertimbangkan sebagai indeks untuk setiap transaksi, Di sisi lain, dataset ini memiliki jumlah ID film yang lebih sedikit daripada dataset peringkat  yang membuat kami memilihnya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tages.movieId.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Rating Film** <br>\n",
    "Dataset ini berisi tag yang ditambahkan ke film ditambah dengan ID pengguna yang bernilai untuk dipertimbangkan sebagai indeks untuk setiap transaksi, Di sisi lain, dataset ini memiliki jumlah ID film yang lebih sedikit daripada dataset peringkat  yang membuat kami memilihnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ratings.movieId.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Preprocessing$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merging Dataset** <br>\n",
    "\n",
    "Dalam kasus ini, inner join dipilih karena kami memerlukan data hanya ketika label movieId ada di kedua dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = data_movies.merge(data_tages,on = 'movieId',how = 'inner')\n",
    "merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop Variable** <br>\n",
    "Drop variabel yang tidak diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.drop(columns=['tag','timestamp','genres'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merge.userId.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Code Task 1**</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di sini Anda dapat melakukan preprocessing dataset untuk membuat daftar transaksi di mana setiap baris mewakili seorang pengguna dan film yang dipilihnya menggunakan groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_list = pass\n",
    "\n",
    "merge_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Validasi daftar yang dibuat per userId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merge.userId.unique()))\n",
    "print(len(merge_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformasi Data** <br>\n",
    "Di sini data ditransfer sebagai binary input untuk diterima oleh algoritma.<br>\n",
    "Tugas Anda adalah mentransformasi data menjadi binary input dengan metode yang telah Anda eksplor dan beri nama df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Code Task 2**</span><br>\n",
    "Anda bisa menggunakan package apa saja yang telah dipelajari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pass\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Process$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Items <br>\n",
    "Bagian ini mengimplementasikan penggunaan pembuatan itemset sesuai dengan parameter yang dipilih. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Apriori** <br>\n",
    "Tugas Anda adalah membuat kode Apriori dengan nilai minimum support 1%, dan berikan penjelasan dari hasilnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Code Task 3**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori_frequent_itemsets = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori_frequent_itemsets['itemsets'].apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori_frequent_itemsets['support'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Berikan Penjelasanmu Disini!**</span>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fpgrowth** <br>\n",
    "Tugas Anda adalah membuat kode Fpgrowth dari frequent itemset dengan ambang batas nilai support minimum 1%, dan berikan penjelasan dari hasilnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Code Task 4**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgrowth_frequent_itemsets = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgrowth_frequent_itemsets['itemsets'].apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgrowth_frequent_itemsets['support'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Berikan Penjelasanmu Disini!**</span>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rule<br>\n",
    "Buatlah fitur baru yang dapat digunakan untuk analisis lebih lanjut, dengan menerapkan association rule dari hasil algoritma sebelumnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Code Task 5**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Code Task 6**</span><br>\n",
    "Urutkan nilai berdasarkan confidence dan lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[rules[\"antecedents\"].apply(lambda x: \"Inception (2010)\" in str(x))].groupby(\n",
    "    ['antecedents', 'consequents'])[['confidence']].max().sort_values(ascending=False,\n",
    "                                                                      by='confidence').head(10).plot(kind='bar').invert_xaxis()\n",
    "plt.title('Top movies that are likley to be watched with inception');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Berikan Penjelasanmu Disini!**</span>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Visualisasi  Association  Rules  with   (Networkx)$ <br>\n",
    "(FYI Exploring the result)<br>untuk melihat visualisasi jaringan antar film berdasarkan aturan asosiasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules['antecedents'] = rules.antecedents.apply(lambda x: next(iter(x)))\n",
    "rules['consequents'] = rules.consequents.apply(lambda x: next(iter(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "edges = nx.from_pandas_edgelist(rules.sort_values(ascending=False,by='lift')\n",
    "                           ,source='antecedents',target='consequents',edge_attr=None)\n",
    "pos = nx.spring_layout(edges, seed=42)  # use spring_layout instead\n",
    "# Add edges as scatter trace\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in edges.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "fig.add_trace(edge_trace)\n",
    "\n",
    "# Add nodes as scatter trace\n",
    "node_x = []\n",
    "node_y = []\n",
    "node_text = []\n",
    "for node in edges.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "    node_text.append(node)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=False,\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        line_width=2))\n",
    "\n",
    "node_trace.text = node_text\n",
    "fig.add_trace(node_trace)\n",
    "\n",
    "# Set layout and display the figure\n",
    "fig.update_layout(\n",
    "    title='Top 100 movies in term of (lift)',\n",
    "    title_font_size=25,\n",
    "    font_size=18,\n",
    "    showlegend=False,\n",
    "    hovermode='closest',\n",
    "    margin=dict(b=20,l=5,r=5,t=40),\n",
    "    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
